Рассмотрим двумерную случайную величину $(X, У)$, где $X$ и $Y$ — зависимые случайные величины. Представим одну из величин как функцию другой. Ограничимся приближенным представлением величины $Y$ в виде линейной функции величины $X$: 

$Y \approx g(X) = \alpha X + \beta$ , где $\alpha$  и $\beta$ - параметры подлежащие определению.

Функцию $g(X)= \alpha X + \beta$ называют «наилучшим приближением» $Y$ в смысле метода наименьших квадратов, если математическое ожидание $M (Y - g(X))^2$ принимает
наименьшее возможное значение; функцию $g(X)$ называют среднеквадратической регрессией $Y$ на $X$.

Линейная средняя квадратическая регрессия $Y$ на $X$ имеет вид

$g(X) = m_y + r \frac{\sigma_y}{\sigma_x}(X - m_x)$, где $m_x = M(X)$, $m_y = M(Y)$, $\sigma_x = \sqrt{D(X)}$, $\sigma_y = \sqrt{D(Y)}$, $r = \mu_{xy} / (\sigma_x\sigma_y)$ — коэффициент корреляции величин $X$ и $Y$. 

$r \frac{\sigma_y}{\sigma_x}$ - коэффициент регрессии $X$ на $Y$.
